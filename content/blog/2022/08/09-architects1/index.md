---
title: "Architects Part 1" 
date: "2022-08-17T00:00:00.169Z"
description: "Naming is hard. The title of 'Architect' is one with a storied history. From fish tales, to epic 
journeys, to ghoulish nightmares technology architect responsibilities and roles are hard to pin down. In part one, 
I aim to provide the tools that can be used for tech and non-tech folk alike to communicate and work together to
help staff these roles as well as to evaluate how they fit into your organization."
---

According to the Google search (definitions provided by [Oxford Languages](https://languages.oup.com/google-dictionary-en)

ar·chi·tect
/ˈärkəˌtekt/
noun
1. a person who designs buildings and in many cases also supervises their construction.
_"the great Norman architect of Durham Cathedral"_

2. COMPUTING
a person who designs hardware, software,
   or networking applications and services of a specified type for a business or other organization.
_"we are seeking an experienced software architect to join our scientific computing team"_
3. verb COMPUTING
design and configure (a program or system).
_"few software packages were architected with Ethernet access in mind"_

`Similar:
designer
planner
builder
building consultant
draftsman`

Welp. That's all there is to see here. Short article!

---

Naturally, I'm kidding. 

There are books, articles, blogs, vlogs and possibly a feature length film entirely devoted to the conversations and
debates surrounding the definition of an architect within technological pursuits. 

There are some fantastic concepts throughout all of these materials, and despite the advancements in technology, the
core concepts of many of these definitions and perspectives are centered largely around the same basic topics.
This suggests that there is some truth within the brevity we can enjoy from the definition provided above. While 
simple definitions forego the necessity of details and specificity, there is an incredible value of being able to 
provide high-level, general definitions. These buckets of classification are integral characteristics of complicated
systems with many moving parts. In some cases these buckets provide stability of separate, but similar, concepts to allow
for comparisons. Yet in other cases, these buckets act as barrier to concepts that aren't related, allowing our limited
brains the relief from taxation from scope that we simply cannot provide a commanding sense of focus. In summary, the
ability to stumble upon simple definitions provides sure footing to large, telescoping concepts that can quickly 
exceed our fleeting attention spans. 

Transparently, I'm not a fan of the term.
I don't like the terms engineer or architect.
In some respects, I feel that the "naming is hard" school of thought has misrepresented naming as esoteric,
leading to the borrowing of nomenclature established for other purposes.
Engineers and architects in the traditional sense built things that were intended to stand 
the test of time as opposed to the dynamic iteration presented by modern technology streams.
I've always concerned each and every person working in a technological field as a capital-T Technologist.
Whether you are configuring applications for operations organizations, writing code,
or designing some*thing*, you are all technologists aligned in some form towards a common goal.  

However, a one-size-fits-all name isn't pragmatic as it pertains to the reality of human resources,
[tech ladders ](https://github.com/jorgef/engineeringladders) skill assessments,
core competency management and many of the other necessary mechanisms for building and scaling organizations.
At some point, we have to descend into the details so that people leaders have a sandbox from which to
establish expectations and accountabilities for the tasks that aggregate up to the organizational deliverables

Many architect roles today are preceded by a classifying noun.
This classifier is a meta-term used to distinguish the efforts of a role as it is affixed to the direction and goals of 
a larger organization, business unit or team. 

Those nouns are a construct that has resulted from the yin and yang of hiring managers, human resources teams and
talent professionals over the course of many years.
The result is a somewhat challenging landscape for younger versions of the aforementioned people: 
especially talent professionals.

Logistically, it is the kind of problem that is fixable on paper. However, it would require consensus of the entire
industry and some form of rigid body to enforce it. History frowns on rigidity of this nature. In reality, people en
masse are excellent at creating chaos and herculean messes. Serendipitously, we are also good at making sense of those
messes and solving challenges... even the ones of our own creation.

I've divided part 1 into two sections

1. I'm going to try to define what an architect is at a high level and provide three basic categories of architectural 
work. 
2. I'm going to compare and contrast an architect with an engineer to elucidate the differences so we can establish a 
bird's eye view of accountability across technological quanta.  

This is a scenic tour. 
It is hard to understand
how a role fits in the greater organism of a business without understanding or questioning the organism.
There are easter eggs, and I'm going to try to do my best to make sure there
are links to all of them.
I'd love for this to be a reference, but if it's just a fun ride through the country with the 
windows rolled down on a breezy afternoon of the dog days of summer, that's a worthy consolation!

---

# Architect: The Job. 

Architects are responsible for the design of something. 
Some architects might focus on one of these areas, and others might be balanced in various ratios across two or all.
These responsibilities are categorized based on the output being generated and a generic paradigm used to provide this 
output.

It's also important to recognize, that while these categories represent the best form of decomposition for the roles
in order to discuss them in terms of recruiting and hiring, there is also plenty of cross over and leakage within
the definitions. Like most things that exist in nature, there are glorious imperfections! 

My goal is to do the most good by aiming for the normalized distribution of roles. 
For those outside the inter-quartile range, the tails, or even the outliers, I apologize if I've missed you. 

This exercise is not intended to establish some long term nomenclature or language, but rather to provide a temporary
ontological view of architectural work that I believe helps frame the discussion relative to hiring, team building, 
scaling and other organizational efforts. 

## 1. Architecting Something To Do: Process Artifact

Creating process used to be a top-down, ivory tower endeavor.
It was the brainchild of senior leadership, 
created in conference rooms and monotonous cubicle farms to be disseminated through email and internal content management 
systems. 
Over time, bottoms-up approaches led to the integration of feedback and autonomous working models Old processes became 
challenged by those with intimate proximity to work being done.
Eventually the continuous improvement paradigm wafted through the industry like the warm smell of pie baking on a 
crisp Autumn day, and the table was full once it was served!

As these concepts 
([Lean](https://en.wikipedia.org/wiki/Lean_manufacturing),[Agile](https://en.wikipedia.org/wiki/Agile_software_development),
[DevOps](https://en.wikipedia.org/wiki/DevOps), [Lean Startup](https://en.wikipedia.org/wiki/The_Lean_Startup), 
and various sub-categories of each) grew and matured, adoption was varied. 
Early adopters may have been met with a greater degree of the pain coming from immature process. 
However they were also the contributors towards its maturity, 
and inevitably enjoyed a faster velocity once the experience matured from ["it sucks!" to "it rocks!"](https://nealford.com/memeagora/2009/08/05/suck-rock-dichotomy.html). 
This catapulted those early adopters ahead of their competitors. 

Late adopters and skeptics cite a number of reasons.
Many of the case studies I've read outline two common circumstances: a fear of change, and classic ignorance. 
The latter is a fairly common human condition. 
We might read an article on something, form a judgement based on that information, 
and then fail to allow our judgement to evolve or mature with the object of the opinion. 
Time passes, and our opinion is based on the article we read quite some time ago, while the object has matured. 

Regardless of the initial reasons, organizations often find themselves at a disadvantage. 
Some organizations have so much inertia due to the sheer mass (size) of the organization, that change is painfully slow. 
Many of these juggernauts are able 
to rumble forward due to the momentum of what was effective process prior to procedural innovation. 
In other words, if all things were equal,
the disadvantage would result in the organization falling behind almost immediately. 
Realistically, all things aren't equal, so they have a burn rate at which they can operate at that disadvantage before
they begin to actually fall behind.
Watching the history of leading tech companies from 2000 to present demonstrates this phenomenon. 

This also notes some of the traits that 
[Eric Ries](http://www.startuplessonslearned.com/) observed when codifying the Lean Startup: smaller companies can 
change more easily than large companies. 

Not all companies enjoy the ability to operate at a disadvantage for an extended period of time. 
Those organizations need some kind of spark to reignite their process so that they don't fall far enough behind that
they become obsolete.
Entire career paths were constructed to facilitate some of these transformations.
One of the first examples of a career that comes to mind is an [Agile Coach](https://theagilecoach.com/). 

The scope doesn't have to be as vast as Agile or other software development life cycle practices. 
It can also be decomposed into smaller good practices.
[Trunk-Based Development](https://trunkbaseddevelopment.com/)? 
[Test-Driven Development](https://en.wikipedia.org/wiki/Test-driven_development)?
Anything that falls into the categories of [ways of working](https://www.atlassian.com/practices) are potential areas 
for this kind of architecture.
As we'll discuss later there are tactical and strategic elements that play into architectural roles. 


Realistically speaking, most architects will be involved in some shape or form with internal process, especially if
the organization is supportive of the [continuous improvement](https://en.wikipedia.org/wiki/Continual_improvement_process) ideology. When writing requirements for a position and
eventually staffing it, it is important to ask yourself: 
- Is process central or adjacent to the primary responsibilities of this position? 
- Are we inviting a change agent into the company?
- will this person be focused on delivery something that will require
changes in order to be realized?

An important note about measuring process is that it is very relative.
Even with perfectly executed surveys that collect data with precision, 
no loss, and a universally accepted representation of quantitative data, 
the measurement is only as useful as the population from which it originates. 
In other words, we ultimately measure process based on those who execute with the most desirable traits: 
velocity, quality, safety, etc. 
Those traits may be influenced differently by domain, size, region, and a number of other features, 
diluting the ability to compare and contrast process across organizations.


### Change Agents: Architects of Process
 
A change agent, for the purposes of this article, is an external party who has been invited to affect change upon an 
organization. 
This person is being brought in because their experience and background is in concepts and skills that are 
either non-existent or sparse within the organization as it exists today.
In some cases, the skills do exist,
but they may exist in the leaves of the organizational hierarchy 
(i.e. junior individual contributors, 
lower levels of management) resulting in silence for [fear of speaking against the existing process or culture](https://en.wikipedia.org/wiki/Culture_of_fear#In_the_workplace). 

Inviting a person to the organization in order to change existing process is an indirect statement that the existing 
process (and possibly the people who created them) is not effective, is stale or has some other attribute that requires
it to be changed. 
The propensity for challenge is increased if the author(s) of the existing processes are still with the company. 
A role centered around 
[transformation](https://en.wikipedia.org/wiki/Business_transformation) or change is a likely invitation for conflict. 

I dropped the C-word. 
Some who are reading this probably heard war drums as soon as I mentioned conflict. 
Some of you also know that it doesn't have to go down that road.
[Conflict can be managed](https://en.wikipedia.org/wiki/Conflict_management), 
and even be positive if we address it as part of our strategy for change. 


While on the subject, here are a few things to consider when creating a role of this nature: 

#### It might be worth testing buy-in before creating the position. 

    It doesn't hurt (us) to send a canary in the mine. 
    (It's not so great for the canary.)

Running surveys,
compiling [retro](https://en.wikipedia.org/wiki/Retrospective#Software_development) results,
etc. might be a way to build an internal story to help guide you on a mission of change.

#### Do you have a plan to address conflict? 

If this is only a checkbox on a task list, it is likely to fail spectacularly.
Think  about how hard it is for you as a single person to make a change.
Now, consider what the effort looks like when you need an entire team or organization to change in harmony.

Conflict management when considered with organizational transformation is a slow burn. 
It involves people, who are wonderfully messy, emotional and unpredictable.
**Can you afford that [time](https://en.wikipedia.org/wiki/Time_management)?**

Time and completion are also interesting covariants.
We rarely need full completion of a project immediately. 
Good problem solving requires the ability 
to [decompose](https://en.wikipedia.org/wiki/Decomposition_(computer_science)) complex problems into smaller easily 
understood puzzles. 
Small changes are also easier for us to accommodate. 
Consider this when addressing a plan to mitigate conflict. 

Baby steps!

At the end of the article I'm going to discuss strategy and tactics. This is a good topic to exercise both. 

#### How entrenched is the previous process? 

- Are you a startup that hasn't formalized any process? 
- Are you a Fortune 500 organization with 75,000+ employees who have been doing the same thing for 30 years? 
- How old is the average employee? 
- What are their backgrounds? 
- Do you have people who understand the changes you want to make already in your organization? 
- What is the average tenure of your employees? 
- What is the average tenure of your leadership? 
- Have there been previous attempts to change? 
- What were the results? 
- How did the organization behave? 

Understanding the identity of your organization as it pertains to change is an important part of the journey.
The larger question of this section is concerned with the magnitude of a vector.
How strong is the existing polarity of your organization? 
Is this something a single person can manage, or is it something that is going to require drilling
strategic holes, placed with mathematical precision across the organization to bring down a larger wall of resistance? 

If this is a greater pursuit than a single person, then consider a broader hiring strategy. 
Forgive me for a moment for nibbling at my own dog food, 
but if the transformation behaves like old corroded battery terminals that just won't
budge, then don't hesitate to reach out to a consulting firm. 

[That's what we're here for!](https://www.thoughtworks.com/)

#### Are you willing to commit to change? 

Changing an organization has subtext that we can't ignore. 
There will be people in your organization who came to the organization because of the organizational identity
that existed prior to the change you are attempting to make. 

Some of those people are going to be supportive of the change immediately. 
Some of them are going to take some [coaxing](https://www.betterup.com/blog/resistance-to-change#:~:text=it%20more%20effectively.-,What%20is%20resistance%20to%20change%3F,in%20fear%20of%20the%20unknown.). 
Some of them will be resistant, quietly. 
Some of them will be resistant... not-quietly. 

How does the change you are going to make impact your organizational vision, culture and values? 
I've never encountered a circumstance where the answer is "It doesn't".
It might be small, it might even appear to be insignificant. 
Sometimes small changes have a larger effect than we anticipate. 

You are going to have people in the organization who don't want to come with you on the next phase of this journey. 
That's ok. 
It is very important to handle this with compassion.
Let them go.
Help them if you can.
Try your very best not to make them feel left behind. 

In some cases, the changes we make aren't just driven by the needs of the organization.
Sometimes they are driven by an industry standard.
Even in these cases, you can't force someone to come along.
You can certainly provide them data and justification for the changes. 
However, if they aren't convinced that the industry is moving in the direction you are, 
the only thing you can do is let them find out for themselves. 

This might seem off the beat and path, but I assure you it isn't. 
Architects are leaders, which makes organizational culture one of their primary responsibilities.
I believe that an organization's culture begins a mile away from the front door. 
This means that even the most precursory recruitment discussions, sales relationships, and external vendor 
relationships are just as important as the relationship between peers or managers and direct reports. 

Just the same, when an employee exits -- for whatever reason -- they should be allowed their dignity, privacy and a 
policy of assuming the best of intent. 
Today's "immature kid" may be tomorrow's "model leader".

### Change as a Side Dish: Architects who Affect Process

Alternative to change agents, are the architects who have one of the other two core focuses I'm going to discuss later. 
In these cases, process is something that they may or may not have to address as a part of their job function. 

More often than not, this type of change is a cooperative effort. 
Architects work with product managers, engineering
leadership, executives, and so on to create a multi-dimensional surface to change that blankets an organization. 

This kind of change catalyst is more amorphous or organic than the singular notion of an agent. 
When I discussed change agents as a role, 
I mentioned that they were often brought in due to the lack (or sparseness) of skills/concept within an organization. 
This may only be true in part. 

Some organizations that don't possess the expertise or skills of a desired change, are able to drive transformative
strategy without bringing in external influences.
The difference is in attitude and openness.
This is why I emphasized the likelihood of conflict in the previous section.
When a single change agent is brought into a company it is often due to the fact
that the company has an internally-fixated view of process.
The employees are less likely to look outside of the box (or organization) for other views or perspectives. 

Change by committee is easier to accomplish when you've built an organization with teams that are willing to learn new 
things, are open to new ideas, and seek inspiration from multiple sources. 
This type of [generative culture](https://cloud.google.com/architecture/devops/devops-culture-westrum-organizational-culture) is often
considered to be the ideal culture, because rather than being bound to a specific implementation of an idea or process,
it is focused on organizational relationship with performance-focused outcomes.
It shirks pathology and bureaucracy.  


----

I want to address what might appear as a sprinkle of bias towards these concepts. 
As I mentioned earlier, I'm targeting the peak of the bell curve. 
Most organizations that are able to change effectively don't create roles centered around
transformation, because they have been able to achieve it without doing so.
(I alluded to this towards the end of the previous section.)

A single change agent is expensive.
The skill set is hard to find because it requires extensive experience,
understanding of what good and bad process looks like (in many different domains and organizations),
and it requires substantial emotional intelligence and behavioral competence. 
Beyond that, the landscape of an organization that is facing these
challenges is likely not to be an easy (or even welcome) environment to walk into. 
Assuming you are able to find someone who **can** do the job, 
it is still a fractional group among those who can who are likely to be **willing**. 

Beyond the expense of staffing the role, any unilateral change effort is going to collide with business as usual, 
resulting in temporary loss of productivity (the length and degree of which are proportional to the cooperation of
the existing organization and the efficacy of the change agent). 

In part 2, I'm going to discuss the concept of a Transformation Architect. 
These roles are divided by the nature of the result, being technical or non-technical.
Much of the efforts discussed here have to do with the challenges of human interaction. 

## 2. Architecting Something To Be Created: Autonomous Artifact 

When we think of architects, we think of them as people who bring something into existence. 
There is something creative associated with the title or role.
A problem is presented, and the architect is responsible for providing a solution. 

In this specific case, a new autonomous artifact is being created. 


### What is an artifact?

For the purposes of this definition we are focusing not only on the end result (i.e. what is being provided), but also
the effort and resources put into the creation of it.
Technically speaking, all three categories of the ontology I'm providing 
(Process Artifact, Autonomous Artifact, Assembled Artifact) create an artifact.
The first is easily distinguishable from the latter two, because it is a procedure or way of working.
The latter two are harder to tell apart, because they might very well be used by end users in the same manner.
In order to tell the difference you have to pop the hood. 

I understand this might be a departure from common definitions, however for the purposes of defining roles we're
not just concerned with Oz, but which yellow brick road we've taken to get there. 

### What does "new" mean? 

For a moment let's think about a car. 
When a new model of a car is designed, it becomes the template for future iterations of that model. 
In fact, many models are already derived from other models.
One of my favorite cars is the Plymouth Barracuda. 
The first-generation of that model was released in 1964.
Each year, a new version of that model was released until it was discontinued after 1974. 

Certain traits of the vehicle were modified over time, and others remained the same.
In fact, the body of the car itself was derived from the pre-existing Chrysler "A-body" platform.

This isn't unlike the pattern orientation associated with many architects.
We beg, borrow and steal patterns from across the industry 
that have a demonstrated capability to solve problems that have the same dimensions as the ones we are solving. 

When I started writing this, I initially wrote same _domain_ instead of same _dimensions_. 
However,
it occurred to me
that many breakthroughs have come from out-of-the box thinking that applies patterns created in the context of one
domain to problems of similar _shape and size_ from other domains. 

#### Invention vs. Iteration

In terms of defining **new**, 
invention is an extreme circumstance where we are ultimately plodding through territory that has never been visited. 
We are approaching problems that have characteristics that aren't addressed by existing patterns and schools of thought.
To reach back to the ca" example above, this might have been the creation of the Chrysler A platform, 
which became the base for several dozen of Chrysler's cars for roughly thirty years. 

Invention yields to iteration, where existing patterns are optimized or compared with alternative solutions.
Each of the cars that were constructed atop that platform discovered issues, gaps, 
outliers and oddities with the design that needed to be addressed. 
Some of those issues were systematic, requiring a change for all of the vehicles derived from the platform. 
In other cases, the issues were more localized to the specific model due to it's specification.

Just as a new car can be created wholly from pre-existing patterns, templates and ideas, a newly designed artifact can 
be constructed entirely of well-scrutinized patterns and approaches while still being considered new. 

I'm going to use another "I" word. Innovation. 
Those of us learning from the brilliance of times gone past are often referred to as "standing on the shoulders of giants".
We are building on the tools and ideas that were left for us, 
and hopefully planting the seed for the foundation of innovation for future generations. 


### Where do we draw the line? 

The reason to discuss "newness" will become more apparent when I discuss the Autonomous Artifact Test. 

As mentioned in the preceding section, we are likely to be utilizing frameworks, tools, libraries, patterns etc. that 
already exist as we execute to create an artifact. 
Is there a threshold or line of _creational effort_ 
that must be reached for the artifact to have earned the lofty adjective: **new**? 

Historically, that line has been drawn by the word **code**. 
Artifacts were often the brain child of software developers, comprised of many lines of code.
In contrast, assembly was largely a paste-and-glue effort performed through scripts and configuration. 

This brief sentence is often one of the problems differentiating those tasks. 
I don't want to dip into a full scale assault onto the traditional development/operations friction, but a quick pit
stop is warranted.
Development teams often dismiss the complexity and effort that goes into operation work,
just as operations teams often dismiss the weeds of software development.
Despite some levels of crossover between their roles, they are ultimately two very different categories of technologist.


Scripts and configuration files (especially 10-15 years ago) were possibly an order of magnitude more terse than lines
of code. 
There was little to no boilerplate, or scaffolding for object orientation, design patterns etc. 
A well written script is ultimately a checklist in executable form.
Many of these scripts were migrated from manually implemented runbooks.
Over time, they evolved to have controls to stop on failure or prompt for different patterns of execution.
However, they usually don't demonstrate a commanding knowledge of algorithms, data structures etc. 

It is beyond the scope of this article to dive into this further, but it is important to understand how very deep the
challenges between operations and engineering teams.
Their goals are in direct conflict.
The nature of their work is close enough to tempt the assertion of assumptions and conjecture about the other. 
Even the psychology of people driven to each career has certain characteristics that make conflict a possibility.

#### What's Code?

Code is such a vague term, even in software, that it is very challenging to have a fruitful, pointed discussion where
the word itself serves as an effective identifier.
I'd rather talk about 'why is code'...

[Low Code? ](https://en.wikipedia.org/wiki/Low-code_development_platform)
[No Code? ](https://www.nocode.tech/)
These concepts actually require code. 
They don't describe some magical tool that generates code from brainwaves.
They are tools designed to compete with application frameworks to lower the level of entry into creation space.
The [very first web apps](https://www.businessinsider.com/flashback-this-is-what-the-first-website-ever-looked-like-2011-6#:~:text=The%20first%20web%20page%20went,%2FWWW%2FTheProject.html.) were written in low-level languages, back when we weren't very good at creating programming
languages (code!!!).
Eventually languages evolved to get better at certain categories of ... code. 
Each generational iteration led to better languages.
However, the bar of entry was always an understanding of coding and software.
These newer Low/No Code tools put the power of creation into the hands of people who might have a better understanding
of the business, domain space, specialized customer knowledge and so on. 

Software development has become increasingly simple.
Libraries like [sklearn](https://scikit-learn.org/stable/),
[nltk](https://www.nltk.org/), 
[pandas](https://pandas.pydata.org/), 
[numpy](https://numpy.org/) etc. have made [Python](https://www.python.org/)
a scientific, data-wrangling, AI/ML powerhouse.
Tools like [Project Lombok](https://projectlombok.org/) and frameworks like [Spring](https://spring.io/),
[Micronaut](https://micronaut.io/) and 
[Quarkus](https://quarkus.io/) have accelerated developer productivity by
providing service harnesses to abstract away non-business focused code, abating tiresome boilerplate, and providing
declarative capabilities using annotations. 

Infrastructure has exploded in every direction.
Configuration management, deployment and maintenance has become easier and easier with declarative
[YAML](https://yaml.org/) or [JSON](https://www.json.org/json-en.html) driven manifests.
[HashiCorp](https://www.hashicorp.com/) and the [CNCF (Cloud Native Computing Foundation)](https://www.cncf.io/) have
an entire business model focused on (mostly) simplifying these areas.
However, just the same, there are also technologies that require substantial development in areas that might have
once been driven with less scrutinized code.
As an example, 
[Kubernetes](https://kubernetes.io/) has led to the creation of a number of new standards surrounding 
[compute](https://opencontainers.org/),
storage, and other
technical features that have required adjustments to accommodate [containerization](https://en.wikipedia.org/wiki/OS-level_virtualization), 
[orchestration](https://en.wikipedia.org/wiki/Orchestration_(computing)), 
[immutable infrastructure](https://www.hashicorp.com/resources/what-is-mutable-vs-immutable-infrastructure)
etc.


More often than not, our focus and goals aren't to spend money, time and effort in the plumbing of a system, but rather
to be focused on the specific problems of the organization or business.
There is almost a tide-like ebb and flow of complexity as new concepts emerge in the raw and older concepts mature and
simplify.


[This guy](https://en.wikipedia.org/wiki/Samuel_Morse) might have an idea. 
For technologists, code is nothing more than a tool in a toolkit. 

#### What is code... doing?

What is that code (in whatever shape or form it appears) doing?
I believe that this is the single most important differentiator.
Does the code being written have a direct relationship
to the problem(s)) defined by the mission statement of the organization trying to provide a product or service in
pursuit of the solution of said problem? 

If the answer is yes, then this is an autonomous architect. 

If the answer is no, then this _may_ not be an autonomous architect.

The easiest way to differentiate this is with what I call the "Autonomous Artifact Test"

    If the sole purpose of the code is NOT only to assemble or 
    otherwise integrate two or more pre-exisitng artifacts.

    AND 

    The code can not exist on its own outside of the environment for 
    which it was created.

    It can not stand on its own two legs, and is therefore 
    not an artifact. 



Let's investigate the contrary. 
Consider the case of plumbing and infrastructure. 
Many of [Google](https://developers.google.com/)'s most famous technologies
(i.e. [BigTable](https://en.wikipedia.org/wiki/Bigtable), 
[GFS](https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf))
were never directly released for public consumption. 
Those technologies were created somewhere along their journey for providing optimizations for the
[search engine](http://infolab.stanford.edu/~backrub/google.html).

Many organizations today, even large ones, don't go to the same lengths to solve problems for their customers. 
Instead, 
they leverage the best of breed technologies available at any given time in order to optimize their business expenses. 
Distributed systems are hard, especially the further you swim from the surface.
The expertise required to build those types of environments isn't easy to find, and expensive to boot. 

This is one of the most critical reasons that cloud computing has become the force that it has.
It subtracts much of the technical complexity that you don't need 
(or want) to be involved with so that you can focus all of your human
capital on your mission statement and business problems. 
(It is also better for technology as a whole, because it accelerates innovation and discovery.)

So, how do we come up with a definitive answer?
Autonomous or Not? 
I look at the relationship of the architect to the artifact.
I deliberately used Google's previously mentioned artifacts as an example, 
because there are open source projects 
([HBase](https://hbase.apache.org/) and [HDFS](https://hadoop.apache.org/) respectively)
that were created and inspired by the BigTable and GFS by
[Doug Cutting](https://en.wikipedia.org/wiki/Doug_Cutting) and
[Mike Cafarella](https://en.wikipedia.org/wiki/Mike_Cafarella) while at Yahoo.
Cutting is also the co-founder of [Lucene](https://en.wikipedia.org/wiki/Apache_Lucene) which is the 
underlying core of [Elasticsearch](https://www.elastic.co/).
I outlined this relationship as another example of how the creation of one tool (Lucene) might help facilitate the
development of a tool (Elasticsearch) that provides simplicity and better abstraction.
The beauty of this process is that we aren't throwing out the baby with the bath water or boiling oceans.
Instead we are layering, refactoring, and **reusing**. 
While I'm geeking out,
the SSTable (Sorted Strings Table) is a central storage concept to LSM( Log Structured Merge) Tree data stores. 
[This article](http://distributeddatastore.blogspot.com/2013/08/cassandra-sstable-storage-format.html) goes into
its relationship to BigTable and [Cassandra](https://cassandra.apache.org/_/index.html).
I cited this article which might help trace back Cutting's involvement with BigTable.
The SSTable structure was also used for Lucene, suggesting that he used this concept to bootstrap many different tools. 

Each of these technologies passes the Autonomous Artifact test, suggesting that the relationship can be compositional. 
He created (with help?) a tool (an autonomous artifact) which was used to create further tools (new autonomous artifacts).

If you step back to get a wider view, it's interesting to see how so many different technologies were almost quite
literally grown from the same seed. 

Speaking of seeds to branches, the first design document for HDFS was created by 
[Dhruba Borthakur](https://scholar.google.com/citations?user=NYgWyv0AAAAJ&hl=en) while also at Yahoo, 
who would later be known for his work on [RocksDB](http://rocksdb.org/) while at
[Facebook](https://developers.facebook.com/).
RocksDB **also** happens to be an LSM based distributed datastore leveraging SSTables.
Many of you might not have heard of RocksDB, however if you flip through the 
[wikipedia](https://en.wikipedia.org/wiki/RocksDB) article, you'll note that it is the storage engine for many well 
known data stores. 

Why does this matter? 
When Yahoo was bootstrapping Hadoop the business wasn't focused on storage, neither was Google when it created BigTable
and GFS, nor was Facebook when it created RocksDB.
These were all means to an end to gain an edge.
The companies had evolved into more than just an organization that solves business problems.
They emerged as **technology companies** that optimize and innovate the way those problems are solved.
This is one of the ways to prevent commoditization (or at the very least to delay it for a while).
The compositional nature of artifacts I mentioned above is a case of "I have to make a thing to make the other thing."
or "I have to make a thing to improve the other thing."

Technology, as Shrek says, is like ogres. 
They have layers. This is the nature of the autonomous artifact test, and 
why it can't be evaluated on it's relationship to the business alone.

At the time BigTable and GFS were created, it is likely that the impact on technology as a whole couldn't have been
accurately predicted to be what it has been.
Maybe these companies knew that they were trying to innovate.
Maybe they were just trying to solve a problem, because they wanted to solve it better than the existing technology
allowed for.
Maybe companies set out to be "technology organizations", or maybe they just get their organically due to a drive
to excel.
At some point Google became more than "find things on the internet!".
The following links don't go to the organizations, but rather links to technologies that they are responsible for
providing:
[Facebook](https://reactjs.org/)?
[Uber](https://www.jaegertracing.io/), 
[LinkedIn](https://kafka.apache.org/) and [again](https://datahubproject.io/),
[Lyft](https://www.amundsen.io/),
[Netflix](https://netflix.github.io/)?
and so many more.

These projects all pass the Autonomous Artifact Test.

---

As mentioned in the first category,
an architect who creates autonomous artifacts may not be the only function of the role.
The purpose of the ontology is define some basic high level categories of work.
It is not only possible, but highly probable that there will need to be changes to existing processes, and some form of
assembly or integration along the way. 
This is especially true with the prevalence of modern distributed systems
architectures where old, middle-aged and new components are constantly being sunset and born at different rates. 

If I can revisit the initial question _What is an artifact?_, I like to think of it as a living, breathing animal of 
the technology world. 
It is autonomous... and it can bite you if you don't feed it regularly.

## 3. Architecting Something To Be Put Together: Assembly Artifact 

Last, but certainly not least is the effort of assembly. 
This category of architect is more concerned about piecing things together, 
and less about the creation of something new.
If the assembly results in something new, that's ok, assembly as a concept doesn't prohibit this.
The point is less about the end state of what is being created, and more about the path to getting there. 

This is a more straightforward concept, but before we leave it, I'd like to talk about one of the more interesting
roles that might be earmarked for this category.
Classic "systems integration" 
is often the creation of a hardware artifact or device from a collection of sub components.
An example might be your laptop, or a NAS system, a guitar amplifier, a smart phone and so on.
In many cases, 
companies purchase all of the sub-components of the aforementioned devices
without manufacturing any of them on their own. 

Those very same companies hire someone (usually several someones) to design the assembly and integration of these parts
into a final artifact. 

The reason I mention this example is that in many cases, their efforts pass the "Autonomous Artifacts Test".
Much of the code created for these systems might be custom firmware, BIOS, bloatware (Smart Phones!) and so on.
While these bits and
pieces of code may be optimized for the system they are being designed for, many of them can be used 
outside of that environment. 

So why did I discuss something which breaks my own model?:

First and foremost, as a reminder that this model is intended to be organic and elastic.
It is simply impossible to 
address every possible circumstance.
The Autonomous Artifact Test is a very basic way to differentiate between
two loosely defined categories of design work.
The line is not absolute, and that's ok. 

Additionally, I intentionally prefixed the words "system integration" above with "classic".
Books and older technical
texts use this term, but it has somewhat fallen out of fashion over the past few decades.
Given common usage (or lack thereof), I feel some comfort in referring to a classic "systems integration" 
as an autonomous artifact architecture. 

Like the previous two categories, assembly or integration can be a part of a multi-faceted role, or it could very
much be the entirety of a role.
Assembly in the case of process or artifacts is often a set of tasks that occurs
as part of a complicated design process.
Distributed applications might require integration and assembly of the various
artifacts.
A process that requires the coordination of multiple business units may have smaller procedures that
aggregate up to a larger, more comprehensive process. 

There are cases where integration or assembly happens on its own.
These efforts are very common when working with infrastructure, cloud service providers,
and other pre-existing artifacts being glued together for some purpose.

----

# Architects and Engineers

I promised to compare and contrast the roles of architects and engineers. 
As with previous discussions, I have to emphasize that there is no absolute set of guidelines. 
These roles are contextual and circumstantial. 

## Directional Technologists: Horizontals and Verticals. 

There are many euphemisms, analogies, metaphors and phrases used to differentiate the concepts of depth and breadth in
technological value streams.
I'm sure you've heard reference to the "T-shaped" organization, or skill sets "a mile wide and an inch deep".
Perhaps you might have heard the phrase "jack of all trades, master of none".

All too often, we get caught up in the title rather than the responsibilities of a role. 

### Depth: The Vertical Skill Set.

Many of us began our career journeys fixing bugs.
Prior to the accessibility and maturity of code analysis tools such as [SonarQube](https://www.sonarqube.org/),
the foray into programming often began with a game of follow-the-leader.
Junior engineers spent time investigating defects.
The ultimate value was that in the pursuit of resolving accidental errors, they were building 
good practices through code study from presumably more experienced engineers. 

There were a number of challenges with this approach. 
- The process was contradictory as junior engineers were studying the code written by those who had performed the errors
under investigation: This was a conflict of interests,
  creating doubt over the degree of "good" amongst the good practices being learned.
- The nature of "good practices" was subjective, anecdotal and based on the assumption that the code was of high quality,
the person writing the code was more experienced, etc. 

Think back to a process of paying dues by working your way through teams like "sustaining engineering" or "customer 
engineering" or even QA teams before you were assigned to work on a dev team (or to write new code).
Systems Engineers often spent their time as Systems Administrators or mission critical support representatives
(Does anyone remember Product IT?) before becoming "generative" technologists. 

If we fast forward to modern streams, we'll find more entry level devs and ops engineers generating non-defect related
contributions due to the advent of the aforementioned tooling.
[DevOps](https://www.youtube.com/watch?v=LdOe18KhtT4), and the concept of "bringing the pain forward" 
or "shift left" brings test automation and code analysis so early into the pipeline and development stage, that it has 
truly reinvented not only the way we develop, but the way that developers build and evolve their own skill sets. 

Code analysis tools no longer represent an opinionated approach of a select few senior engineers across an organization.
Instead, it represents industry-wide good practices that become cemented into the way we create technological content.

#### Code Review: Then and Now

Think back to Code Reviews of yesteryear.
Prior to modern tooling,
there was a period of convergence required of dev teams and organizations to agree upon what was readable code.
Encyclopedic style guides were created that endured the jagged life of going stale, being updated, going stale, 
being updated, ad infinitum
(Usually, each cycle resulted in a greater percentage of leftover typos, staleness, and errors)

These code reviews became interrupt driven, and conflict riddled due to the tension of personal opinions, unstable
documentation practices, and the entropy of the industry as a larger population. 

Now, with modern tooling, style is enforced mechanically, creating a configuration driven watchdog for readability and
syntax.
They don't catch every mistake, but they do help us catch the dumb ones, which are usually the ones our eyes miss the
most. 
Very much like the difference between artifact and assembly,  modern code reviews are concerned less with 
peripheral aspects of the business, honing in on the patterns, technologies, algorithms and approaches that present
the shortest possible distance from problem to solution. 

Learning and context, as a function of career growth,has increased considerably.
Pull requests and code reviews have become
dinosaurs, as the tooling prevents breakage and simple error from entering production.
There is less need to spend time reviewing code looking for errors that will be found by customers in production,
as these tools and automation spits simple failure back onto its creators. 

Newer methodologies such as desk check, showcase, increased test automation and so on find ways to isolate and verify
more advanced, problem specific concepts within the codebase.

#### So what does this have to do with depth?

Engineers spend less time in meta-practices, and more time entrenched in the problem space.
Their focus and sponge-like minds are spent in these spaces much longer than they would otherwise.
An engineer working on a team that has been built around a specific problem will quickly become competent and expert at 
that given problem with the capacity for more pointed depth than the engineers of prior generations due to the removal
of obstacles and ancillary details.

Imagine, if you will, a cone or cylinder of buried treasure embedded deep into the Earth's crust, such that the value of
the buried treasure increases proportional to its depth.
This is the life of an engineer on a dev team.
As they spend more time on a given team,
their understanding of the problem that team has been constructed to solve increases in detail and articulation.
However, just the same, this is a hole.
That depth often (but not always) will come at the cost of seeing the problems of other holes (or dev teams). 

Humans have a finite capacity to retain information, ie. "Use it or lose it."
Given such finite mental capacity,
it is logical to suggest that endeavors focused on vertical or depth-driven knowledge,
may come at the cost of a horizontal or breadth-driven perspective. 


### Breadth: Horizontal Skill Set

Education, especially one established in traditional liberal arts, is an iterative approach that continues to 
present deeper, more detailed, concepts year over year. 
Computer science isn't entirely different.
There are several pillars of knowledge considered essential to a given career pursuit.
Prospective engineers chase the educational hierarchy throughout college, bootcamps, etc.
Once we start earning a paycheck, that pursuit continues.
Sometimes depth driven learning continues out of sheer momentum.
Once a task is placed in front of us, we focus and conquer!
And then another, and then another. 

The human brain is simply amazing.
Some people can focus on tasks ad infinitum without losing interest or wavering in any way shape or form.
Others don't. 

What drives someone to switch gears or skills on a frequent enough basis to construct multi-tooled repertoires? 
- Is it a high aptitude? 
- Is it possible that someone just "gets it", and further descent on a subject provides no further intrinsic growth or development?
- Is it boredom?
- Is there just some chemical difference in some people's brains
  that creates an ever-increasing itch to pull their heads up from the repetition of deepening tasks?
- Is it fear? or anxiety? or wanderlust? 
- Do we just have to move around? 

- Or is it some combination of these and other possibilities? 

#### Is it the picture in the puzzle, or the puzzle itself? 

Over time, I've had the luxury of working with a lot of very talented and smart technologists.
As a function of that time, 
I'm now old and have had the additional luxury of watching the evolution of those technologists.
Some people have an innate passion about solving a specific problem.
Maybe they love selling things, or [CAD](https://en.wikipedia.org/wiki/Computer-aided_design), or video games. 
Others have a passion for a specific category of problem.
Maybe they love web design or databases.
Some people have a specific passion for a certain tech stack, 
like [JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript) or 
[C](https://en.wikipedia.org/wiki/C_(programming_language))/[C++](https://cplusplus.com/). 


These people tend to hover around those core interests.
The standard deviation from that core varies in proportion to the degree of interest for the core.
Change is possible, and it certainly does happen.
In fact, when they make a change, you might find that it is sometimes quite abrupt.
The person who has spent 20 years in web design suddenly leaps to another endeavor after a sense of completion or finality.
Perhaps it is similar to the likes of a thespian who ends a 
decade-long run as a fan-favorite character? 

Then there is the person who just loves puzzles.
If I can wax romantic for a moment, this is the type of person who
likes the fresh smell of cardboard on the puzzle box, and the sound of the pieces scattering on the table as they dump
them out with cherubic glee.
The domain, language, category probably doesn't matter.
Over time, they'll rule out things that they don't care for, but for the most part, their interests remain open.
This is very much like the hunter who loves the hunt rather than the trophy. 

--- 

If you step back for a moment and look at these mindsets, they both tend to approach some central point of cosmic 
harmony, but from very different perspectives. 

The extreme vertical technologist is oven looking for truth and expertise in the fashion of a straight line. 
Their career journey is as unbending and uninterruptible as possible. 
Deviations can be seen as frustrating and bothersome. 
Decision isn't necessarily a conscious action,
but rather an obvious and logical path set by it's Dijsktra-esque shortest path to their ultimate goal. 

In contrast, the extreme horizontal technologist is driven almost by a FOMO (fear-of-missing-out) perspective.
They must map out every perspective and angle.
In the path to the center,
they must find and map every path and traversable region from the starting point to the inevitable goal. 

In reality, I doubt that a person is represented in totality by only one of these traits.
I imagine that we are a free- flowing ratio that changes over time. 

What changes that ratio is beyond my comprehension.
I've simply seen so many different wonderful people approach technology in different ways,
that I couldn't possibly begin to even opine what drives a personal journey.
I can only enjoy the view, and help someone find their way if they ask.

### Is one better than the other? 

Yes...and No!

Whichever one is right for you is the better one for you.
I want to emphasize this because I think that it is lost on 
many leaders and organizations to encourage one's personal journey without presenting barrier to that discovery.
Find your fit.
Play your game.
Be yourself. 

In terms of an organization?
No.
In fact, in all but the most extremely niche circumstances, we ultimately need both. 
The size and scope of modern distributed systems are so broad they can not possibly be created without a balance of 
both. 

The concept of 
[two-pizza teams](https://docs.aws.amazon.com/whitepapers/latest/introduction-devops-aws/two-pizza-teams.html) 
(or [delivery teams](https://www.bizops.com/blog/the-software-delivery-team)),
supported by [Conway's Law](https://en.wikipedia.org/wiki/Conway%27s_law), is driven by the value of solving
problems at depth.
Frankly, its as logical and intuitive as basic algebra: group the components of equations by the like terms.
Compartmentalization of domain context within a single team helps foster expertise towards an enriched 
understanding of that context.
However, in order to ensure that this component can function as an organ of a larger body of work,
we must have the cross-functional understanding that provides context for interaction of all organs within 
their part-whole relationship of that larger body. 

### Who does what? 

When you consider the matrix of organizations, both as a function of title and level, the concept of horizontal 
technologists and vertical technologists becomes a puzzle unto itself. 

In an ideal world, we would be able to simply write up job descriptions for certain roles, and affix them on top of 
each other to create coverage for the depth and breadth we need for an optimal outcome.
Realistically, based on all of the concepts I've discussed up until now, it isn't that easy. 

People are messy.
Time passes and people change.
Organizations have conflict, and too much depth might offset breadth or vice versa.
By the time we create our utopian matrix, the engineers who had x-level of depth may have reached x * 10 
level of depth, or maybe we've discovered that we hired someone for their depth only to learn they wanted breadth, and
so on.

Artifacts are moving, living, breathing, growing animals. 
Organizations take on a personality, and even with the best laid
plans it is often not identical to the vision that a leader has planned for as they began to build such teams.
The best leaders figure out what matters the most and guide rather than demand,
while allowing non-critical characteristics to evolve and grow as a function of the organization as an organism. 

In short, engineers engineer and architects architect.
Traditionally,
engineers are the depth-focused technologists
who tend to increase their depth with greater passion than their breadth over time.
Likewise,
architects are usually breadth-focused technologists
who have emerged from engineering to grow their breadth with greater passion than their
depth over time.
BUT!
It isn't always true.
There are exceptions. 

However, time and skill is relative.
It isn't uncommon to find an experienced engineer with greater breadth than an inexperienced architect and vice versa. 

If I can reframe the focus of this article on it's ultimate intent: building teams is more about the people than the
documents that describe what they do.
In that regard, I'm going to challenge common thought about the expendability of
employees.
I don't believe they are. 

You can replace a piece of paper.
You can even replace what that piece of paper defines and describes (specifically speaking of a job description).
However you can't replace the entirety of what a person brings to an organization.
The character, relationships, highs, lows, quirks and wonderful weirdness that each person brings to work with them is
not replaceable. 

Consider this when creating a role and job description.
What characteristics do you want to attract?
What relationships do you want to encourage and cultivate?
What highs and lows do you want to see?
Things are always going to be weird.
Make sure it's a fun kind of weird!

### Time: Technology in Three Dimensions

Analysis is often cross-sectional.
Studying biological cells, rates of change in calculus or even diving through logs is often an
exercise in reducing the dimension of time to a halt so we can see what the heck is (was) going on.
Predictive analysis absolutely requires reductive effort to optimize compute resources so that questions get answered
in a reasonable (i.e. useful) amount of time.
It also helps our tiny human brains wrap around concepts that are otherwise hard to visualize or understand.
The previous section is a gargantuan effort
at looking at the matrix of a technology organization's skill sets through dimensions of technical depth and breadth. 

I've touched on time (sparingly) I mentioned briefly at the end of the previous section that these skill sets are in
flux.
Technologists learn new things, forget things they've stopped using and even develop new interests.
This isn't entirely due to the nature of the person or the organization. 

Time is defined in different contexts everywhere. 

There are x working hours in the day, y days in an iteration and z technologists assigned to the work signed off on
for that iteration.
x * y * z = what?
It depends. 

How were the roles defined?
What were the expectations set for each technologist within the organization.
How do
those definitions complement one another such that it provides the necessary coverage for "work to be done"? 

Did the technologists enter the iteration with all of the necessary skills?
Did we account for learning, ramp up time, 
etc.? 

Another aspect of time is career growth. As many iterations pass, technologists level up, move on, are promoted, etc. 

What about the almost entropic pace of innovation?
Many organizations have described the goal of technological innovation
to be "disruptive".
This akin to Mike Tyson's paraphrased statement: "Everyone has a plan until they get hit in the face".

Just as I cited in the section on process, effective technological direction is often measured by the most desirable
characteristics: value, cost, performance, reliability, maintainability, (many-ilities).
Even if you are the poster child for the best of breed today, new technologies can emerge tomorrow.
If that shiny new technology is adopted by your
competitors, you may be forced to course correct to avoid losing economic advantage or stability. 

And yet, there is still more time.
I also mentioned the concept of "standing on shoulders of giants".
As we scramble to understand shiny new technologies, we begin to understand and recognize new patterns.
Those patterns become tested and exercised by almost ritualistic experimentation and application to business problems.
Yesterday's house of cards is tuned to become today's bedrock.

---

## Tacticians vs. Strategists. 

Another bi-dimensional way to view architects is how close they are to the work being done.
Tactical architects tend
to describe roles that have more depth than breadth, and are closer to the details of work being done as opposed to
process, governance and longer-term outlooks.
These roles may be focused on work being done a few sprints ahead, with
a general view of the targeted goals. 

Conversely, strategic architects may be more focused on process and long term goals.
Their focus might be more on business goals, presenting status and challenges to stakeholders, 
gaining alignment from those stakeholders and so on.

### What is (a good) strategy? 

Strategies are "plan artifacts" that are the result of considerable thought and research.
Important characteristics 
of these kinds of artifacts are:
- clearly defined goals that have been carefully and collectively scrutinized by leadership teams.
- strong, verifiable data points that guide decision making. 
- contingencies in the event of failure or the inability to move forward, preferably ordered by probability of success,
or risk. 

Without clear goals, the end state of any business effort will be translucent or even opaque.
If we don't know where we are going, then we won't be able to optimize time researching ways to get there.
Our data points may be strong, but they may not defend the paths necessary to achieve the goals we strive for.
Without clear goals, our primary path will be questionable, let alone any alternate routes. 

If goals aren't clear, then we are far more likely to be plotting a course to failure than success. Failure is easy. 

### What are (good) tactics? 

- Tactics are specific, decomposed compartments that help us get to a strategy.
  Like any big problem, it is easier to understand and act against smaller simpler tasks.
  Take the time to do so. 

- Aim small, fail small.
  As an addendum to the previous note, smaller tasks are easier to recover from.
  The less time we spend, the less time we have lost if the action goes awry.
  While we are on the topic of time, good tasks are time bound.
  When we are working towards goal, our most valuable commodity is time.
  Don't let tasks go on forever.
  If work starts to drag out, stop and figure out why.
  Fix it. 

- Track your progress.
  As you work towards your goal, very much like a GPS system, you want to make sure that you haven't veered off course.
  Using OKRs is one (best?) example of creating a relationship between the short term work and longer term goals. 

### Strategy & Tactics vs. Previous Concepts...

The significance of this additional view is to consider how different architects might fit into an organization or
technological value stream given the aggregation of these dimensions against categorical features such as leveling or
tenure. 

Generally, when we think of tactics, we think of individual contributors or line level management, whereas strategy is
often an increasing responsibility as one climbs the corporate ladder. 

This isn't altogether different from common patterns reflecting the focus of depth against breadth. 
It is really just another lens from which to evaluate a role or organization of tasks and how those tasks can provide
vision and value to the rest of the organization.

### What comes first... the chicken or the strategy? 

(Ok. I mean strategy and tactics!)

Usually, when an organization starts there is a strategy and a business plan that kicks things off.
Once a company begins to execute on that plan, ideally the process becomes cyclical. 

Tactical efforts are more than just steps of execution.
They are probes into efficacy that, with good practices,
can be constructed into a feedback mechanism that helps us fine tune strategic properties over time.
This is the core principle of continuous improvement
and it is one of the simplest tools in our repertoire for binding technical
direction to business planning. 

---

Thanks for joining me for this word salad extravaganza that is part 1 of my foray into a discussion about architects. 

In part 2, I aim to apply the concepts provided here across some of the more common job roles I've seen posted or
defined across job sites, businesses, and even standards organizations.